<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Peng Xia">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2025/05/11/multi-modal-series/clip/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="CLIP - Contrastive Language-Image Pre-training">
<meta property="og:url" content="http://example.com/2025/05/11/Multi-modal-series/CLIP/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/redefine-og.webp">
<meta property="article:published_time" content="2025-05-11T05:22:20.180Z">
<meta property="article:modified_time" content="2025-05-11T05:24:09.792Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="多模态">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/github-color-svgrepo-com.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/github-color-svgrepo-com.svg">
    <meta name="theme-color" content="#FFD700">
    <link rel="shortcut icon" href="/images/github-color-svgrepo-com.svg">
    <!--- Page Info-->
    
    <title>
        
            CLIP - Contrastive Language-Image Pre-training | Sharpen&#39;s Blogs
        
    </title>

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">


    <!--- Inject Part-->
    

    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/css/build/tailwind.css">

    

    
<link rel="stylesheet" href="/fonts/GeistMono/geist-mono.css">

    
<link rel="stylesheet" href="/fonts/Geist/geist.css">

    <!--- Font Part-->
    
        <link href="https://fonts.googleapis.com/css2?family=Lora" rel="stylesheet">
    
    
    
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"3.2rem","h2":"2.4rem","h3":"1.9rem","h4":"1.6rem","h5":"1.4rem","h6":"1.3rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":false,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":{"enable":false,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#FFD700","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/dune.jpg","dark":"/images/dune.jpg"},"title":"Sharpen's Blogs","subtitle":{"text":["Just regularly appending some blogs here, to keep my memory fresh and mind straight.","Here I am. ","Do not go gentle into that good night. "],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":true,"family":"Lora","url":"https://fonts.googleapis.com/css2?family=Lora"},"social_links":{"enable":false,"style":"default","links":{"github":"https://github.com/shar-pen","instagram":null,"zhihu":null,"twitter":null,"email":"xiapeng21011@mail.ustc.edu.cn"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.2","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories","icon":"fa-solid fa-folder"},"About":{"path":"/about","icon":"fa-regular fa-user"},"Links":{"icon":"fa-regular fa-link","submenus":{"Github":"https://github.com/shar-pen","Blog":"https://github.com/shar-pen.github.io","CSDN":"https://blog.csdn.net/the_3rd_bomb"}}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":":)","show_on_mobile":true,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"},"Categories":{"path":"/categories","icon":"fa-regular fa-folder"}}},"article_date_format":"YYYY-MM-DD","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":null};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
                <a class="logo-image h-8 w-8 sm:w-10 sm:h-10 mr-3" href="/">
                    <img src="/images/github-color-svgrepo-com.svg" class="w-full h-full rounded-sm">
                </a>
            
            <a class="logo-title" href="/">
                
                Sharpen&#39;s Blogs
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    ARCHIVES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/categories"
                                        >
                                    <i class="fa-solid fa-folder fa-fw"></i>
                                    CATEGORIES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/about"
                                        >
                                    <i class="fa-regular fa-user fa-fw"></i>
                                    ABOUT
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown"
                                   href="#"
                                        onClick=&#34;return false;&#34;>
                                    <i class="fa-regular fa-link fa-fw"></i>
                                    LINKS
                                    <i class="fa-solid fa-chevron-down fa-fw"></i>
                                </a>

                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://github.com/shar-pen">
                                                    GITHUB
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://github.com/shar-pen.github.io">
                                                    BLOG
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://blog.csdn.net/the_3rd_bomb">
                                                    CSDN
                                                </a>
                                            </li>
                                        
                                    </ul>
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i>
                    </div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                ARCHIVES
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/categories"
                        >
                            <span>
                                CATEGORIES
                            </span>
                            
                                <i class="fa-solid fa-folder fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/about"
                        >
                            <span>
                                ABOUT
                            </span>
                            
                                <i class="fa-regular fa-user fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item-sub text-base my-1.5 flex flex-col w-full">
                        
                        <div class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary cursor-pointer text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                             navbar-data-toggle="submenu-Links"
                        >
                            <span>
                                LINKS
                            </span>
                            
                                <i class="fa-solid fa-chevron-right fa-sm fa-fw transition-all"></i>
                            
                        </div>
                        

                        
                            <div class="flex-col items-start px-2 py-2 hidden" data-target="submenu-Links">
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://github.com/shar-pen">GITHUB</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://github.com/shar-pen.github.io">BLOG</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://blog.csdn.net/the_3rd_bomb">CSDN</a>
                                    </div>
                                
                            </div>
                        
                    </li>
            

            
            
                
                    
                    
                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full active"
                           href="/tags"
                        >
                            <span>Tags</span>
                            <i class="fa-regular fa-tags fa-sm fa-fw"></i>
                        </a>
                    </li>
                
                    
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">9</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">11</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">45</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			<div class="w-full flex items-center pt-6 justify-start">
				<h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">CLIP - Contrastive Language-Image Pre-training</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/avatar.jpg">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">Peng Xia</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2025-05-11 13:22:20</span>
        <span class="mobile">2025-05-11 13:22:20</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-05-11 13:24:09</span>
            <span class="mobile">2025-05-11 13:24:09</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81/">多模态</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/">多模态</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>2.5k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>13 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<p>Learning Transferable Visual Models From Natural Language Supervision paper：<a class="link" target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.00020">https://arxiv.org/abs/2103.00020<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>OpenAI 推出了 CLIP，即 对比式语言-图像预训练（Contrastive Language-Image Pre-training）。简而言之，该模型学习的是整句话与其描述的图像之间的关系；也就是说，当模型训练完成后，给定一段输入文本，它能够检索出与该文本最相关的图像。这里的一个关键点是，它的训练是基于完整句子，而不是单一的类别（例如“汽车”、“狗”等）。其核心直觉在于，使用完整句子进行训练可以让模型学到更多信息，从而在图像与文本之间发现潜在的模式。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/CLIP/1uVUI6bU49oT-nNRGFs4GEA.webp"></p>
<blockquote>
<p>CLIP jointly trains an image encoder and a text encoder to predict the correct pairings of a batch of (image, text) training examples.</p>
</blockquote>
<p>说直白点，就是让 image embedding 和 （与 image 配对的text）的 text embedding 相似度高，与其他不匹配的 text 的 text embedding 相似度低。我们训练对象是 image encoder 和 text encoder，更准确点，我们会用预训练模型作为 encoder，然后在其后面加入 projection head 来将源模态的 embedding 转为为 unified embedding (统一的模态)，encoder 预训练，仅微调，projection head 从头开始训练，这也解决了 embedding 维度不一样的问题。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/CLIP/image-20250511131816188.png" alt="image-20250511131816188"></p>
<blockquote>
<p>At test time the learned text encoder synthesizes a zero-shot linear classifier by embedding the names or descriptions of the target dataset’s classes.</p>
</blockquote>
<p>在实际 zero-shot 分类时，取各个类别转换为 text，经过 text encoder 转换为各个类别的 text embedding。同时，需要分类的 image 经过 image encoder 转换为 image embedding，计算 image embedding 和 text embedding 之前的相似度，softmax 后最高者对应的类别就是分类结果。</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> timm</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer, DistilBertConfig</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"TOKENIZERS_PARALLELISM"</span>] = <span class="string">"false"</span></span><br></pre></td></tr></table></figure></div>

<h2 id="加载-image-caption"><a href="#加载-image-caption" class="headerlink" title="加载 image - caption"></a>加载 image - caption</h2><p>Flicker-8k 数据地址：<a class="link" target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/adityajn105/flickr8k">https://www.kaggle.com/datasets/adityajn105/flickr8k<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p>Flicker-8k 将配对数据保存为 txt，此处读取为 dataframe</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">"./Flicker-8k/Images"</span></span><br><span class="line">captions_path = <span class="string">"./Flicker-8k/captions.txt"</span></span><br><span class="line">train_ratio = <span class="number">0.5</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line">size = <span class="number">224</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataframe = pd.read_csv(captions_path)</span><br><span class="line"><span class="comment"># print(dataframe[:10].to_markdown())</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'num of data:'</span>, <span class="built_in">len</span>(dataframe))</span><br><span class="line">dataframe = dataframe.sample(frac=<span class="number">1</span>, random_state=<span class="number">42</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(dataframe) * train_ratio)</span><br><span class="line">train_dataframe = dataframe[:train_size]</span><br><span class="line">test_dataframe = dataframe[train_size:]</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="left">image</th>
<th align="left">caption</th>
</tr>
</thead>
<tbody><tr>
<td align="right">0</td>
<td align="left">1000268201_693b08cb0e.jpg</td>
<td align="left">A child in a pink dress is climbing up a set of stairs in an entry way .</td>
</tr>
<tr>
<td align="right">1</td>
<td align="left">1000268201_693b08cb0e.jpg</td>
<td align="left">A girl going into a wooden building .</td>
</tr>
<tr>
<td align="right">2</td>
<td align="left">1000268201_693b08cb0e.jpg</td>
<td align="left">A little girl climbing into a wooden playhouse .</td>
</tr>
<tr>
<td align="right">3</td>
<td align="left">1000268201_693b08cb0e.jpg</td>
<td align="left">A little girl climbing the stairs to her playhouse .</td>
</tr>
<tr>
<td align="right">4</td>
<td align="left">1000268201_693b08cb0e.jpg</td>
<td align="left">A little girl in a pink dress going into a wooden cabin .</td>
</tr>
<tr>
<td align="right">5</td>
<td align="left">1001773457_577c3a7d70.jpg</td>
<td align="left">A black dog and a spotted dog are fighting</td>
</tr>
<tr>
<td align="right">6</td>
<td align="left">1001773457_577c3a7d70.jpg</td>
<td align="left">A black dog and a tri-colored dog playing with each other on the road .</td>
</tr>
<tr>
<td align="right">7</td>
<td align="left">1001773457_577c3a7d70.jpg</td>
<td align="left">A black dog and a white dog with brown spots are staring at each other in the street .</td>
</tr>
<tr>
<td align="right">8</td>
<td align="left">1001773457_577c3a7d70.jpg</td>
<td align="left">Two dogs of different breeds looking at each other on the road .</td>
</tr>
<tr>
<td align="right">9</td>
<td align="left">1001773457_577c3a7d70.jpg</td>
<td align="left">Two dogs on pavement moving toward each other .</td>
</tr>
</tbody></table>
<p>每个图片都有 5 个 caption 来描述其内容。</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">"/home/guest/others/data_collection/distilbert-base-uncased"</span>)</span><br><span class="line"><span class="built_in">print</span>(tokenizer(<span class="string">"hello"</span>)) <span class="comment"># {'input_ids': [101, 7592, 102], 'attention_mask': [1, 1, 1]}</span></span><br></pre></td></tr></table></figure></div>

<p>数据集设置很简单，相比于有监督学习的 x 和 y，对比学习是正样本和负样本。以上每一行的 image 和 caption 就是正样本，而负样本是同一 batch 的其他 caption。</p>
<p>虽然严格意义上，我们可能遇到同一 batch 里的两个 image 是一样，但其对应 caption 是语义上类似，但不严格相同的。这种情况下还是会被视为负样本，但考虑到这样的情况很少出现，即很小概率正样本被当作负样本处理，所以整体训练上是没毛病的。</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_transforms</span>(<span class="params">mode=<span class="string">"train"</span></span>):</span><br><span class="line">	<span class="keyword">if</span> mode == <span class="string">"train"</span>:</span><br><span class="line">		<span class="keyword">return</span> A.Compose([</span><br><span class="line">			A.Resize(size, size),</span><br><span class="line">			A.Normalize(max_pixel_value=<span class="number">255.0</span>),</span><br><span class="line">		])</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> A.Compose([</span><br><span class="line">			A.Resize(size, size),</span><br><span class="line">			A.Normalize(max_pixel_value=<span class="number">255.0</span>),</span><br><span class="line">		])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CLIPDataset</span>(torch.utils.data.Dataset):</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_filenames, captions, tokenizer, transforms</span>):</span><br><span class="line">		<span class="string">"""</span></span><br><span class="line"><span class="string">		image_filenames and cpations must have the same length; so, if there are</span></span><br><span class="line"><span class="string">		multiple captions for each image, the image_filenames must have repetitive</span></span><br><span class="line"><span class="string">		file names </span></span><br><span class="line"><span class="string">		"""</span></span><br><span class="line"></span><br><span class="line">		<span class="variable language_">self</span>.image_filenames = image_filenames</span><br><span class="line">		<span class="variable language_">self</span>.captions = <span class="built_in">list</span>(captions)</span><br><span class="line">		<span class="variable language_">self</span>.encoded_captions = tokenizer(</span><br><span class="line">			<span class="built_in">list</span>(captions), padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, max_length=<span class="number">200</span></span><br><span class="line">		)</span><br><span class="line">		<span class="variable language_">self</span>.transforms = transforms</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 每个数据是一个 image 和一个 caption ，准确点是一个 tensor 化的 image 和一个 tokenized 的 caption</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">		item = {</span><br><span class="line">			key: torch.tensor(values[idx])</span><br><span class="line">			<span class="keyword">for</span> key, values <span class="keyword">in</span> <span class="variable language_">self</span>.encoded_captions.items()</span><br><span class="line">		}</span><br><span class="line"></span><br><span class="line">		image = cv2.imread(<span class="string">f"<span class="subst">{image_path}</span>/<span class="subst">{self.image_filenames[idx]}</span>"</span>)</span><br><span class="line">		image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">		image = <span class="variable language_">self</span>.transforms(image=image)[<span class="string">'image'</span>]</span><br><span class="line">		item[<span class="string">'image'</span>] = torch.tensor(image).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).<span class="built_in">float</span>()</span><br><span class="line">		item[<span class="string">'caption'</span>] = <span class="variable language_">self</span>.captions[idx]</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.captions)</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_loaders</span>(<span class="params">dataframe, tokenizer, mode, batch_size=<span class="number">32</span>, num_workers=<span class="number">4</span></span>):</span><br><span class="line">	transforms = get_transforms(mode=mode)</span><br><span class="line">	dataset = CLIPDataset(</span><br><span class="line">		dataframe[<span class="string">"image"</span>].values,</span><br><span class="line">		dataframe[<span class="string">"caption"</span>].values,</span><br><span class="line">		tokenizer=tokenizer,</span><br><span class="line">		transforms=transforms,</span><br><span class="line">	)</span><br><span class="line">	dataloader = torch.utils.data.DataLoader(</span><br><span class="line">		dataset,</span><br><span class="line">		batch_size=batch_size,</span><br><span class="line">		num_workers=num_workers,</span><br><span class="line">		shuffle=<span class="literal">True</span> <span class="keyword">if</span> mode == <span class="string">"train"</span> <span class="keyword">else</span> <span class="literal">False</span>,</span><br><span class="line">	)</span><br><span class="line">	<span class="keyword">return</span> dataloader</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">train_loader = build_loaders(train_dataframe, tokenizer, mode=<span class="string">"train"</span>, batch_size=batch_size)</span><br><span class="line">valid_loader = build_loaders(train_dataframe, tokenizer, mode=<span class="string">"valid"</span>, batch_size=batch_size)</span><br><span class="line"><span class="comment"># print(train_loader.dataset.__getitem__(0))</span></span><br><span class="line"><span class="comment"># print(next(iter(train_loader)))</span></span><br></pre></td></tr></table></figure></div>


<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> a_batch.items():</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">f"key name: <span class="subst">{k}</span>, value data type: <span class="subst">{<span class="built_in">type</span>(v)}</span>, value shape: <span class="subst">{v.shape <span class="keyword">if</span> <span class="built_in">isinstance</span>(v, torch.Tensor) <span class="keyword">else</span> <span class="built_in">len</span>(v)}</span>"</span>)</span><br></pre></td></tr></table></figure></div>


<div class="code-container" data-rel="Markdown"><figure class="iseeu highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">key name: input<span class="emphasis">_ids, value data type: <span class="language-xml"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">torch.Tensor</span>'&gt;</span></span>, value shape: torch.Size([32, 42])</span></span><br><span class="line"><span class="emphasis">key name: attention_</span>mask, value data type: <span class="language-xml"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">torch.Tensor</span>'&gt;</span></span>, value shape: torch.Size([32, 42])</span><br><span class="line">key name: image, value data type: <span class="language-xml"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">torch.Tensor</span>'&gt;</span></span>, value shape: torch.Size([32, 3, 224, 224])</span><br><span class="line">key name: caption, value data type: <span class="language-xml"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">list</span>'&gt;</span></span>, value shape: 32</span><br></pre></td></tr></table></figure></div>

<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><ul>
<li>image encoder 用 resnet 或者 vit，forward不变，返回图片 embedding</li>
<li>text encoder 用 bert 变体 distilbert，foward返回 CLS token 位置的 embedding</li>
<li>两个 projection head 分别把 image embedding 和 text embedding 转换为统一的 embedding</li>
</ul>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ImageEncoder</span>(nn.Module):</span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	Encode images to a fixed size vector</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">		self, model_name=<span class="string">'resnet50'</span>, pretrained=<span class="literal">True</span>, trainable=<span class="literal">True</span>, pretrained_cfg_overlay=<span class="literal">None</span></span></span><br><span class="line"><span class="params">	</span>):</span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">		<span class="variable language_">self</span>.model = timm.create_model(</span><br><span class="line">			model_name, pretrained, num_classes=<span class="number">0</span>, global_pool=<span class="string">"avg"</span>, pretrained_cfg_overlay=pretrained_cfg_overlay</span><br><span class="line">		)</span><br><span class="line">		<span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.model.parameters():</span><br><span class="line">			p.requires_grad = trainable</span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">		<span class="keyword">return</span> <span class="variable language_">self</span>.model(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextEncoder</span>(nn.Module):</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name=<span class="string">"distilbert-base-uncased"</span>, pretrained=<span class="literal">True</span>, trainable=<span class="literal">True</span></span>):</span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">		<span class="keyword">if</span> pretrained:</span><br><span class="line">			<span class="variable language_">self</span>.model = AutoModel.from_pretrained(model_name)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="variable language_">self</span>.model = AutoModel(config=DistilBertConfig())</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.model.parameters():</span><br><span class="line">			p.requires_grad = trainable</span><br><span class="line"></span><br><span class="line">		<span class="comment"># we are using the CLS token hidden representation as the sentence's embedding</span></span><br><span class="line">		<span class="variable language_">self</span>.target_token_idx = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask</span>):</span><br><span class="line">		output = <span class="variable language_">self</span>.model(input_ids=input_ids, attention_mask=attention_mask)</span><br><span class="line">		<span class="comment"># (batch_size, sequence_length, hidden_size)</span></span><br><span class="line">		last_hidden_state = output.last_hidden_state</span><br><span class="line">		<span class="comment"># use CLS token hidden representation</span></span><br><span class="line">		<span class="comment"># return (batch_size, hidden_size)</span></span><br><span class="line">		<span class="keyword">return</span> last_hidden_state[:, <span class="variable language_">self</span>.target_token_idx, :]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProjectionHead</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">		self,</span></span><br><span class="line"><span class="params">		embedding_dim,</span></span><br><span class="line"><span class="params">		projection_dim=<span class="number">256</span>,</span></span><br><span class="line"><span class="params">		dropout=<span class="number">0.1</span></span></span><br><span class="line"><span class="params">	</span>):</span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">		<span class="variable language_">self</span>.projection = nn.Linear(embedding_dim, projection_dim)</span><br><span class="line">		<span class="variable language_">self</span>.gelu = nn.GELU()</span><br><span class="line">		<span class="variable language_">self</span>.fc = nn.Linear(projection_dim, projection_dim)</span><br><span class="line">		<span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">		<span class="variable language_">self</span>.layer_norm = nn.LayerNorm(projection_dim)</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">		projected = <span class="variable language_">self</span>.projection(x)</span><br><span class="line">		x = <span class="variable language_">self</span>.gelu(projected)</span><br><span class="line">		x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">		x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">		x = x + projected</span><br><span class="line">		x = <span class="variable language_">self</span>.layer_norm(x)</span><br><span class="line">		<span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CLIPModel</span>(nn.Module):</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">		self,</span></span><br><span class="line"><span class="params">		image_encoder,</span></span><br><span class="line"><span class="params">		text_encoder,</span></span><br><span class="line"><span class="params">		image_embedding=<span class="number">2048</span>,</span></span><br><span class="line"><span class="params">		text_embedding=<span class="number">768</span>,</span></span><br><span class="line"><span class="params">		temperature=<span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">	</span>):</span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">		<span class="variable language_">self</span>.image_encoder = image_encoder</span><br><span class="line">		<span class="variable language_">self</span>.text_encoder = text_encoder</span><br><span class="line">		<span class="variable language_">self</span>.image_projection = ProjectionHead(embedding_dim=image_embedding)</span><br><span class="line">		<span class="variable language_">self</span>.text_projection = ProjectionHead(embedding_dim=text_embedding)</span><br><span class="line">		<span class="variable language_">self</span>.temperature = temperature</span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, images:torch.tensor, input_ids:torch.tensor, attention_masks:torch.tensor</span>):</span><br><span class="line">		<span class="comment"># Getting Image and Text Features</span></span><br><span class="line">		image_features = <span class="variable language_">self</span>.image_encoder(images)</span><br><span class="line">		text_features = <span class="variable language_">self</span>.text_encoder(</span><br><span class="line">			input_ids=input_ids, attention_mask=attention_masks</span><br><span class="line">		)</span><br><span class="line">		<span class="comment"># Getting Image and Text Embeddings (with same dimension)</span></span><br><span class="line">		image_embeddings = <span class="variable language_">self</span>.image_projection(image_features)</span><br><span class="line">		text_embeddings = <span class="variable language_">self</span>.text_projection(text_features)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Calculating the Loss</span></span><br><span class="line">		logits = (text_embeddings @ image_embeddings.T) / <span class="variable language_">self</span>.temperature</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> logits, image_embeddings, text_embeddings</span><br><span class="line">	</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>


<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">image_encoder = ImageEncoder(</span><br><span class="line">	model_name=<span class="string">'resnet50'</span>,</span><br><span class="line">	pretrained_cfg_overlay=<span class="built_in">dict</span>(file=<span class="string">'/home/guest/others/xp/clip/timm-resnet50/pytorch_model.bin'</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">text_encoder = TextEncoder(</span><br><span class="line">	model_name=<span class="string">"/home/guest/others/data_collection/distilbert-base-uncased"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = CLIPModel(</span><br><span class="line">	image_encoder=image_encoder,</span><br><span class="line">	text_encoder=text_encoder,</span><br><span class="line">	image_embedding=<span class="number">2048</span>,</span><br><span class="line">	text_embedding=<span class="number">768</span>,</span><br><span class="line">	temperature=<span class="number">1.0</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>



<h2 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h2><p>loss 有两种写法</p>
<ol>
<li>CLIP 原文用的就是对角矩阵为 label 的情况，只要分别在 dim0 和 dim1 与 arange(n) 序列作交叉熵计算就行。原文就是这样实现的，以下是论文中的伪代码。</li>
</ol>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/CLIP/image-20250511131223534.png" alt="image-20250511131223534"></p>
<blockquote>
<p>Given a batch of N (image, text) pairs, CLIP is trained to predict which of the N × N possible (image, text) pairings across a batch actually occurred. To do this, CLIP learns a  with high pointwise mutual information as well as the names of all Wikipedia articles above a certain search volume. Finally all WordNet synsets not already in the query list are added.  multi-modal embedding space by jointly training an image encoder and text encoder to maximize the cosine similarity of the image and text embeddings of the N real pairs in the batch while minimizing the cosine similarity of the embeddings of the N^2 − N incorrect pairings.</p>
</blockquote>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">batch_size = image_embeddings.shape[<span class="number">0</span>]</span><br><span class="line">labels = torch.arange(batch_size).to(device)</span><br><span class="line">texts_loss = <span class="variable language_">self</span>.criterion(logits, labels)</span><br><span class="line">images_loss = <span class="variable language_">self</span>.criterion(logits.T, labels)</span><br><span class="line">	</span><br><span class="line">loss = (images_loss + texts_loss) / <span class="number">2.0</span> </span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>还有一种是以 image-image 和 text-text 相似度为 ground truth，对角线肯定相似度很高，另外部分非对角线数据也会根据其实际 image-image 和 text-text 的相似度。这种方式我感觉可以弥补正样本被视为负样本的情况。</li>
</ol>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">images_similarity = image_embeddings @ image_embeddings.T</span><br><span class="line">texts_similarity = text_embeddings @ text_embeddings.T</span><br><span class="line">targets = F.softmax(</span><br><span class="line">	(images_similarity + texts_similarity) / <span class="number">2</span> * <span class="variable language_">self</span>.temperature, dim=-<span class="number">1</span></span><br><span class="line">)</span><br><span class="line">texts_loss = nn.CrossEntropyLoss()(logits, targets)</span><br><span class="line">images_loss = nn.CrossEntropyLoss()(logits.T, targets.T)</span><br><span class="line">loss =  (images_loss + texts_loss) / <span class="number">2.0</span> <span class="comment"># shape: (batch_size)</span></span><br></pre></td></tr></table></figure></div>


<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_batch</span>(<span class="params">model, optimizer, batch, device</span>):</span><br><span class="line"></span><br><span class="line">	optimizer.zero_grad()</span><br><span class="line">	criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">	images = batch[<span class="string">"image"</span>].to(device)</span><br><span class="line">	input_ids = batch[<span class="string">"input_ids"</span>].to(device)</span><br><span class="line">	attention_masks = batch[<span class="string">"attention_mask"</span>].to(device)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># image_embeddings and text_embeddings have same batch size</span></span><br><span class="line">	<span class="comment"># logits is a matrix of shape (batch_size, batch_size)</span></span><br><span class="line">	<span class="comment"># logits[i][j] is the similarity score between image i and text j</span></span><br><span class="line">	logits, image_embeddings, text_embeddings = model(</span><br><span class="line">		images=images,</span><br><span class="line">		input_ids=input_ids,</span><br><span class="line">		attention_masks=attention_masks</span><br><span class="line">	)</span><br><span class="line"></span><br><span class="line">	batch_size = image_embeddings.shape[<span class="number">0</span>]</span><br><span class="line">	labels = torch.arange(batch_size).to(device)</span><br><span class="line">	texts_loss = criterion(logits, labels)</span><br><span class="line">	images_loss = criterion(logits.T, labels)</span><br><span class="line">	loss = (images_loss + texts_loss) / <span class="number">2.0</span> </span><br><span class="line"></span><br><span class="line">	loss.backward()</span><br><span class="line">	optimizer.step()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> loss.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">model, optimizer, dataloader, device</span>):</span><br><span class="line"></span><br><span class="line">	model.train()</span><br><span class="line"></span><br><span class="line">	losses = []</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">		</span><br><span class="line">		batch_loss = train_batch(model, optimizer, batch, device)</span><br><span class="line">		losses.append(batch_loss)</span><br><span class="line"></span><br><span class="line">	ave_loss = np.mean(losses)</span><br><span class="line">	<span class="keyword">return</span> ave_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_batch</span>(<span class="params">model, batch, device</span>):</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">	images = batch[<span class="string">"image"</span>].to(device)</span><br><span class="line">	input_ids = batch[<span class="string">"input_ids"</span>].to(device)</span><br><span class="line">	attention_masks = batch[<span class="string">"attention_mask"</span>].to(device)</span><br><span class="line"></span><br><span class="line">	logits, image_embeddings, text_embeddings = model(</span><br><span class="line">		images=images,</span><br><span class="line">		input_ids=input_ids,</span><br><span class="line">		attention_masks=attention_masks</span><br><span class="line">	)</span><br><span class="line"></span><br><span class="line">	gt = torch.arange(logits.size(<span class="number">0</span>), device=logits.device)</span><br><span class="line">	pred = torch.argmax(logits, dim=<span class="number">1</span>)</span><br><span class="line">	correct = (pred == gt).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> correct / logits.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_epoch</span>(<span class="params">model, dataloader, device</span>):</span><br><span class="line"></span><br><span class="line">	model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">	accs = []</span><br><span class="line"></span><br><span class="line">	<span class="keyword">with</span> torch.no_grad():</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line"></span><br><span class="line">			batch_acc = test_batch(model, batch, device)</span><br><span class="line">			accs.append(batch_acc)</span><br><span class="line"></span><br><span class="line">	ave_acc = np.mean(accs)</span><br><span class="line">	<span class="keyword">return</span> ave_acc</span><br></pre></td></tr></table></figure></div>

<h2 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h2><p>这里考虑到 image encoder 和 text encoder 都是已经预训练的，而 projection head 是从 scatch 开始训的，所以最好设置 encoder 的学习率较低， projection head 的学习率为正常值。</p>
<div class="code-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">20</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:1"</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)</span></span><br><span class="line">optimizer = torch.optim.AdamW([</span><br><span class="line">	{<span class="string">"params"</span>: model.image_encoder.parameters(), <span class="string">"lr"</span>: <span class="number">1e-5</span>},</span><br><span class="line">	{<span class="string">"params"</span>: model.text_encoder.parameters(), <span class="string">"lr"</span>: <span class="number">1e-5</span>},</span><br><span class="line">	{<span class="string">"params"</span>: model.image_projection.parameters(), <span class="string">"lr"</span>: <span class="number">1e-3</span>},</span><br><span class="line">	{<span class="string">"params"</span>: model.text_projection.parameters(), <span class="string">"lr"</span>: <span class="number">1e-3</span>},</span><br><span class="line">])</span><br><span class="line">lr_scheduler = torch.optim.lr_scheduler.StepLR(</span><br><span class="line">	optimizer, step_size=<span class="number">5</span>, gamma=<span class="number">0.5</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line"></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">f"Epoch: <span class="subst">{epoch + <span class="number">1</span>}</span>"</span>)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">f'Learning Rate: <span class="subst">{lr_scheduler.get_last_lr()[<span class="number">0</span>]}</span>'</span>)</span><br><span class="line">	</span><br><span class="line">	train_loss = train_epoch(model, optimizer, train_loader, device)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">f"Train Loss: <span class="subst">{train_loss:<span class="number">.4</span>f}</span>"</span>)</span><br><span class="line"></span><br><span class="line">	test_acc = test_epoch(model, valid_loader, device)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">f"Test Accuracy: <span class="subst">{test_acc:<span class="number">.4</span>f}</span>"</span>)</span><br><span class="line">	</span><br><span class="line">	lr_scheduler.step()</span><br><span class="line">	<span class="comment"># break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<div class="code-container" data-rel="Markdown"><figure class="iseeu highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 1</span><br><span class="line">Learning Rate: 1e-05</span><br><span class="line">100%|██████████| 633/633 [02:00&lt;00:00,  5.27it/s]</span><br><span class="line">Train Loss: 2.2545</span><br><span class="line">100%|██████████| 633/633 [00:50&lt;00:00, 12.64it/s]</span><br><span class="line">Test Accuracy: 0.7001</span><br><span class="line">Epoch: 2</span><br><span class="line">Learning Rate: 1e-05</span><br><span class="line">100%|██████████| 633/633 [02:07&lt;00:00,  4.98it/s]</span><br><span class="line">Train Loss: 0.7770</span><br><span class="line">100%|██████████| 633/633 [01:08&lt;00:00,  9.23it/s]</span><br><span class="line">Test Accuracy: 0.8489</span><br><span class="line">Epoch: 3</span><br><span class="line">Learning Rate: 1e-05</span><br><span class="line">100%|██████████| 633/633 [02:18&lt;00:00,  4.58it/s]</span><br><span class="line">Train Loss: 0.4705</span><br><span class="line">100%|██████████| 633/633 [01:04&lt;00:00,  9.77it/s]</span><br><span class="line">Test Accuracy: 0.9080</span><br><span class="line">Epoch: 4</span><br><span class="line">Learning Rate: 1e-05</span><br><span class="line">100%|██████████| 633/633 [01:53&lt;00:00,  5.56it/s]</span><br><span class="line">Train Loss: 0.3176</span><br><span class="line">100%|██████████| 633/633 [00:50&lt;00:00, 12.51it/s]</span><br><span class="line">Test Accuracy: 0.9228</span><br><span class="line">Epoch: 5</span><br><span class="line">Learning Rate: 1e-05</span><br><span class="line">100%|██████████| 633/633 [01:57&lt;00:00,  5.40it/s]</span><br><span class="line">Train Loss: 0.2462</span><br><span class="line">100%|██████████| 633/633 [00:51&lt;00:00, 12.20it/s]</span><br><span class="line">Test Accuracy: 0.9343</span><br></pre></td></tr></table></figure></div>
		</div>

		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/">#多模态</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/2025/05/16/Multi-modal-series/ViT/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">ViT - vision transformer</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/2025/05/09/torch-distributed-series/autocast_mixed_precision/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">AMP - Automatic Mixed Precision</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
		<div class="comment-container px-2 sm:px-6 md:px-8 pb-8">
			<div class="comments-container mt-10 w-full ">
    <div id="comment-anchor" class="w-full h-2.5"></div>
    <div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">
        Comments
    </div>
    

        
            
    <div id="waline"></div>
    <script type="module" data-swup-reload-script>
      import { init } from '/js/libs/waline.mjs';

      function loadWaline() {
        init({
          el: '#waline',
          serverURL: 'https://example.example.com',
          lang: 'zh-CN',
          dark: 'body[class~="dark-mode"]',
          reaction: false,
          requiredMeta: ['nick', 'mail'],
          emoji: [],
          
          
        });
      }

      if (typeof swup !== 'undefined') {
        loadWaline();
      } else {
        window.addEventListener('DOMContentLoaded', loadWaline);
      }
    </script>



        
    
</div>

		</div>
		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
	<div class="post-toc">
		<div class="toc-title">On this page</div>
		<div class="page-title">CLIP - Contrastive Language-Image Pre-training</div>
		<ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BD-image-caption"><span class="nav-text">加载 image - caption</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-text">模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0"><span class="nav-text">训练函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="nav-text">训练流程</span></a></li></ol>

	</div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Peng Xia</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        45 posts in total
                    </span>
                    
                        <span>
                            149.4k words in total
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span>
        </div>
        
        
        
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
		<li class="go-comment">
			<i class="fa-regular fa-comments"></i>
		</li>
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	
	<div class="search-pop-overlay">
	<div class="popup search-popup">
		<div class="search-header">
			<span class="search-input-field-pre">
				<i class="fa-solid fa-keyboard"></i>
			</span>
			<div class="search-input-container">
				<input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input">
			</div>
			<span class="popup-btn-close">
				<i class="fa-solid fa-times"></i>
			</span>
		</div>
		<div id="search-result">
			<div id="no-result">
				<i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
			</div>
		</div>
	</div>
</div>
	

</main>



<script src="/js/build/libs/Swup.min.js"></script>

<script src="/js/build/libs/SwupSlideTheme.min.js"></script>

<script src="/js/build/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/build/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/build/libs/SwupScrollPlugin.min.js"></script>

<script src="/js/build/libs/SwupPreloadPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	
<script src="/js/build/tools/imageViewer.js" type="module"></script>

<script src="/js/build/utils.js" type="module"></script>

<script src="/js/build/main.js" type="module"></script>

<script src="/js/build/layouts/navbarShrink.js" type="module"></script>

<script src="/js/build/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/build/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/build/layouts/categoryList.js" type="module"></script>



    
<script src="/js/build/tools/localSearch.js" type="module"></script>




    
<script src="/js/build/tools/codeBlock.js" type="module"></script>




    
<script src="/js/build/layouts/lazyload.js" type="module"></script>






  
<script src="/js/build/libs/Typed.min.js"></script>

  
<script src="/js/build/plugins/typed.js" type="module"></script>








    
<script src="/js/build/libs/anime.min.js"></script>





    
<script src="/js/build/tools/tocToggle.js" type="module" data-swup-reload-script=""></script>

<script src="/js/build/layouts/toc.js" type="module" data-swup-reload-script=""></script>

<script src="/js/build/plugins/tabs.js" type="module" data-swup-reload-script=""></script>




<script src="/js/build/libs/moment-with-locales.min.js" data-swup-reload-script=""></script>


<script src="/js/build/layouts/essays.js" type="module" data-swup-reload-script=""></script>





	
</body>

</html>